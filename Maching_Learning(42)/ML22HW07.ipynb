{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5cFq_TgWlQ_"
   },
   "source": [
    "# Homework 11 - Transfer Learning (Domain Adversarial Training)\n",
    "\n",
    "> Author: Arvin Liu (r09922071@ntu.edu.tw)\n",
    "\n",
    "若有任何問題，歡迎來信至助教信箱 kafuchino0410@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNiZCGrIYKdR"
   },
   "source": [
    "# Readme\n",
    "\n",
    "\n",
    "這份作業的任務是Transfer Learning中的Domain Adversarial Training。\n",
    "\n",
    "<img src=\"https://i.imgur.com/iMVIxCH.png\" width=\"500px\">\n",
    "\n",
    "> 也就是左下角的那一塊。\n",
    "\n",
    "## Scenario and Why Domain Adversarial Training\n",
    "你現在有Source Data + label，其中Source Data和Target Data可能有點關係，所以你想要訓練一個model做在Source Data上並Predict在Target Data上。\n",
    "\n",
    "但這樣有什麼樣的問題? 相信大家學過Anomaly Detection就會知道，如果有data是在Source Data沒有出現過的(或稱Abnormal的)，那麼model大部分都會因為不熟悉這個data而可能亂做一發。 \n",
    "\n",
    "以下我們將model拆成Feature Extractor(上半部)和Classifier(下半部)來作例子:\n",
    "<img src=\"https://i.imgur.com/IL0PxCY.png\" width=\"500px\">\n",
    "\n",
    "整個Model在學習Source Data的時候，Feature Extrator因為看過很多次Source Data，所以所抽取出來的Feature可能就頗具意義，例如像圖上的藍色Distribution，已經將圖片分成各個Cluster，所以這個時候Classifier就可以依照這個Cluster去預測結果。\n",
    "\n",
    "但是在做Target Data的時候，Feature Extractor會沒看過這樣的Data，導致輸出的Target Feature可能不屬於在Source Feature Distribution上，這樣的Feature給Classifier預測結果顯然就不會做得好。\n",
    "\n",
    "## Domain Adversarial Training of Nerural Networks (DaNN)\n",
    "基於如此，是不是只要讓Soucre Data和Target Data經過Feature Extractor都在同個Distribution上，就會做得好了呢? 這就是DaNN的主要核心。\n",
    "\n",
    "<img src=\"https://i.imgur.com/vrOE5a6.png\" width=\"500px\">\n",
    "\n",
    "我們追加一個Domain Classifier，在學習的過程中，讓Domain Classifier去判斷經過Feature Extractor後的Feature是源自於哪個domain，讓Feature Extractor學習如何產生Feature以**騙過**Domain Classifier。 持久下來，通常Feature Extractor都會打贏Domain Classifier。(因為Domain Classifier的Input來自於Feature Extractor，而且對Feature Extractor來說Domain&Classification的任務並沒有衝突。)\n",
    "\n",
    "如此一來，我們就可以確信不管是哪一個Domain，Feature Extractor都會把它產生在同一個Feature Distribution上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-qnUkspmap3"
   },
   "source": [
    "# Data Introduce\n",
    "\n",
    "這次的任務是Source Data: 真實照片，Target Data: 手畫塗鴉。\n",
    "\n",
    "我們必須讓model看過真實照片以及標籤，嘗試去預測手畫塗鴉的標籤為何。\n",
    "\n",
    "資料位於[這裡](https://drive.google.com/file/d/1e4CaQ5VUF3F04XRDGXrnRQGogo89TiF8/view?usp=sharing)，以下的code分別為下載和觀看這次的資料大概長甚麼樣子。\n",
    "\n",
    "特別注意一點: **這次的source和target data的圖片都是平衡的，你們可以使用這個資訊做其他事情。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DF-i0sVlnUbq",
    "outputId": "ae51558f-9e36-4b9b-f502-12a876fa3503"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ['USERPROFILE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "0_uO-ZSDoR6i",
    "outputId": "16892677-3705-4c2e-d898-979b0e85ed32"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def no_axis_show(img, title='', cmap=None):\n",
    "  # imshow, and set the interpolation mode to be \"nearest\"。\n",
    "  fig = plt.imshow(img, interpolation='nearest', cmap=cmap)\n",
    "  # do not show the axes in the images.\n",
    "  fig.axes.get_xaxis().set_visible(False)\n",
    "  fig.axes.get_yaxis().set_visible(False)\n",
    "  plt.title(title)\n",
    "\n",
    "titles = ['horse', 'bed', 'clock', 'apple', 'cat', 'plane', 'television', 'dog', 'dolphin', 'spider']\n",
    "plt.figure(figsize=(18, 18))\n",
    "for i in range(10):\n",
    "  plt.subplot(1, 10, i+1)\n",
    "  fig = no_axis_show(plt.imread(f'C:/Users/terry/desktop/real_or_drawing/train_data/{i}/{500*i}.bmp'), title=titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "3eMs7DbVt4Ee",
    "outputId": "df0ff103-e8fe-465a-a21e-55ff4e053ee4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "for i in range(10):\n",
    "  plt.subplot(1, 10, i+1)\n",
    "  fig = no_axis_show(plt.imread(f'C:/Users/terry/desktop//real_or_drawing/test_data/0/' + str(i).rjust(5, '0') + '.bmp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moXQw9To5TqZ"
   },
   "source": [
    "# Special Domain Knowledge\n",
    "\n",
    "因為大家塗鴉的時候通常只會畫輪廓，我們可以根據這點將source data做點邊緣偵測處理，讓source data更像target data一點。\n",
    "\n",
    "## Canny Edge Detection\n",
    "算法這邊不贅述，只教大家怎麼用。若有興趣歡迎參考wiki或[這裡](https://medium.com/@pomelyu5199/canny-edge-detector-%E5%AF%A6%E4%BD%9C-opencv-f7d1a0a57d19)。\n",
    "\n",
    "cv2.Canny使用非常方便，只需要兩個參數: low_threshold, high_threshold。\n",
    "\n",
    "```cv2.Canny(image, low_threshold, high_threshold)```\n",
    "\n",
    "簡單來說就是當邊緣值超過high_threshold，我們就確定它是edge。如果只有超過low_threshold，那就先判斷一下再決定是不是edge。\n",
    "\n",
    "以下我們直接拿source data做做看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "mn2MkDLV7E2-",
    "outputId": "b506cd2a-ace8-4dc3-814d-ec6e6bf64fd3"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "titles = ['horse', 'bed', 'clock', 'apple', 'cat', 'plane', 'television', 'dog', 'dolphin', 'spider']\n",
    "plt.figure(figsize=(18, 18))\n",
    "\n",
    "original_img = plt.imread(f'C:/Users/terry/desktop/real_or_drawing/train_data/0/0.bmp')\n",
    "plt.subplot(1, 5, 1)\n",
    "no_axis_show(original_img, title='original')\n",
    "\n",
    "gray_img = cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY)\n",
    "plt.subplot(1, 5, 2)\n",
    "no_axis_show(gray_img, title='gray scale', cmap='gray')\n",
    "\n",
    "gray_img = cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY)\n",
    "plt.subplot(1, 5, 2)\n",
    "no_axis_show(gray_img, title='gray scale', cmap='gray')\n",
    "\n",
    "canny_50100 = cv2.Canny(gray_img, 50, 100)\n",
    "plt.subplot(1, 5, 3)\n",
    "no_axis_show(canny_50100, title='Canny(50, 100)', cmap='gray')\n",
    "\n",
    "canny_150200 = cv2.Canny(gray_img, 150, 200)\n",
    "plt.subplot(1, 5, 4)\n",
    "no_axis_show(canny_150200, title='Canny(150, 200)', cmap='gray')\n",
    "\n",
    "canny_250300 = cv2.Canny(gray_img, 250, 300)\n",
    "plt.subplot(1, 5, 5)\n",
    "no_axis_show(canny_250300, title='Canny(250, 300)', cmap='gray')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8THSdt_hmwYh"
   },
   "source": [
    "# Data Process\n",
    "\n",
    "在這裡我故意將data用成可以使用torchvision.ImageFolder的形式，所以只要使用該函式便可以做出一個datasets。\n",
    "\n",
    "transform的部分請參考以下註解。\n",
    "<!-- \n",
    "#### 一些細節\n",
    "\n",
    "在一般的版本上，對灰階圖片使用RandomRotation使用```transforms.RandomRotation(15)```即可。但在colab上需要加上```fill=(0,)```才可運行。\n",
    "在n98上執行需要把```fill=(0,)```拿掉才可運行。 -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZHIBGknmi8Z"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "source_transform = transforms.Compose([\n",
    "    # Turn RGB to grayscale. (Bacause Canny do not support RGB images.)\n",
    "    transforms.Grayscale(),\n",
    "    # cv2 do not support skimage.Image, so we transform it to np.array, \n",
    "    # and then adopt cv2.Canny algorithm.\n",
    "    transforms.Lambda(lambda x: cv2.Canny(np.array(x), 170, 300)),\n",
    "    # Transform np.array back to the skimage.Image.\n",
    "    transforms.ToPILImage(),\n",
    "    # 50% Horizontal Flip. (For Augmentation)\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # Rotate +- 15 degrees. (For Augmentation), and filled with zero \n",
    "    # if there's empty pixel after rotation.\n",
    "    transforms.RandomRotation(15, fill=(0,)),\n",
    "    # Transform to tensor for model inputs.\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    # Turn RGB to grayscale.\n",
    "    transforms.Grayscale(),\n",
    "    # Resize: size of source data is 32x32, thus we need to \n",
    "    #  enlarge the size of target data from 28x28 to 32x32。\n",
    "    transforms.Resize((32, 32)),\n",
    "    # 50% Horizontal Flip. (For Augmentation)\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # Rotate +- 15 degrees. (For Augmentation), and filled with zero \n",
    "    # if there's empty pixel after rotation.\n",
    "    transforms.RandomRotation(15, fill=(0,)),\n",
    "    # Transform to tensor for model inputs.\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "source_dataset = ImageFolder('C:/Users/terry/desktop/real_or_drawing/train_data', transform=source_transform)\n",
    "target_dataset = ImageFolder('C:/Users/terry/desktop/real_or_drawing/test_data', transform=target_transform)\n",
    "\n",
    "source_dataloader = DataLoader(source_dataset, batch_size=32, shuffle=True)\n",
    "target_dataloader = DataLoader(target_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(target_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdwDEMrOycs5"
   },
   "source": [
    "# Model\n",
    "\n",
    "Feature Extractor: 典型的VGG-like疊法。\n",
    "\n",
    "Label Predictor / Domain Classifier: MLP到尾。\n",
    "\n",
    "相信作業寫到這邊大家對以下的Layer都很熟悉，因此不再贅述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uw2eP09z-pD"
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x).squeeze()\n",
    "        return x\n",
    "\n",
    "class LabelPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LabelPredictor, self).__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        c = self.layer(h)\n",
    "        return c\n",
    "\n",
    "class DomainClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DomainClassifier, self).__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        y = self.layer(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxdBIPhF0Icb"
   },
   "source": [
    "# Pre-processing\n",
    "\n",
    "這裡我們選用Adam來當Optimizer。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrxKelBy0PJ7"
   },
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor().cuda()\n",
    "label_predictor = LabelPredictor().cuda()\n",
    "domain_classifier = DomainClassifier().cuda()\n",
    "\n",
    "class_criterion = nn.CrossEntropyLoss()\n",
    "domain_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer_F = optim.Adam(feature_extractor.parameters())\n",
    "optimizer_C = optim.Adam(label_predictor.parameters())\n",
    "optimizer_D = optim.Adam(domain_classifier.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuAE4cqJ0itR"
   },
   "source": [
    "# Start Training\n",
    "\n",
    "\n",
    "## 如何實作DaNN?\n",
    "\n",
    "理論上，在原始paper中是加上Gradient Reversal Layer，並將Feature Extractor / Label Predictor / Domain Classifier 一起train，但其實我們也可以交換的train Domain Classfier & Feature Extractor(就像在train GAN的Generator & Discriminator一樣)，這也是可行的。\n",
    "\n",
    "在code實現中，我們採取後者的方式。\n",
    "\n",
    "## 小提醒\n",
    "* 原文中的lambda(控制Domain Adversarial Loss的係數)是有Adaptive的版本，如果有興趣可以參考[原文](https://arxiv.org/pdf/1505.07818.pdf)。\n",
    "* 因為我們完全沒有target的label，所以結果如何，只好丟kaggle看看囉:)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRAFFKvX0p9y",
    "outputId": "971389bf-0399-454e-b5dd-d9bd19d85c13",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▍                                                                                 | 1/200 [00:07<24:22,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0: train D loss: 0.6382, train F loss: 0.0191, acc 0.9934\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                                 | 2/200 [00:14<24:49,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1: train D loss: 0.6212, train F loss: 0.0181, acc 0.9932\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▏                                                                                | 3/200 [00:22<24:45,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   2: train D loss: 0.5898, train F loss: 0.0097, acc 0.9948\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                                | 4/200 [00:30<24:43,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   3: train D loss: 0.5857, train F loss: 0.0020, acc 0.9960\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██                                                                                | 5/200 [00:37<24:45,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   4: train D loss: 0.5764, train F loss: 0.0077, acc 0.9942\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                               | 6/200 [00:45<24:35,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   5: train D loss: 0.5825, train F loss: -0.0033, acc 0.9946\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▊                                                                               | 7/200 [00:53<24:28,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   6: train D loss: 0.5748, train F loss: -0.0066, acc 0.9950\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▎                                                                              | 8/200 [01:00<24:21,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   7: train D loss: 0.5775, train F loss: -0.0125, acc 0.9950\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▋                                                                              | 9/200 [01:08<24:15,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   8: train D loss: 0.6305, train F loss: 0.0824, acc 0.9788\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████                                                                             | 10/200 [01:16<24:17,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   9: train D loss: 0.6142, train F loss: -0.0143, acc 0.9926\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▍                                                                            | 11/200 [01:23<24:06,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  10: train D loss: 0.5896, train F loss: -0.0252, acc 0.9958\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                            | 12/200 [01:31<23:56,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  11: train D loss: 0.6006, train F loss: -0.0300, acc 0.9958\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████▎                                                                           | 13/200 [01:39<23:52,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  12: train D loss: 0.6132, train F loss: -0.0345, acc 0.9954\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▋                                                                           | 14/200 [01:46<23:51,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  13: train D loss: 0.6120, train F loss: -0.0364, acc 0.9946\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████                                                                           | 15/200 [01:54<23:45,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  14: train D loss: 0.6197, train F loss: -0.0347, acc 0.9934\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                          | 16/200 [02:02<23:37,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  15: train D loss: 0.6183, train F loss: -0.0394, acc 0.9932\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▉                                                                          | 17/200 [02:10<23:33,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  16: train D loss: 0.6227, train F loss: -0.0398, acc 0.9930\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▎                                                                         | 18/200 [02:17<23:23,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  17: train D loss: 0.6331, train F loss: -0.0478, acc 0.9928\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▋                                                                         | 19/200 [02:25<23:17,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  18: train D loss: 0.6264, train F loss: -0.0563, acc 0.9950\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 20/200 [02:33<23:19,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  19: train D loss: 0.6243, train F loss: -0.0603, acc 0.9952\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▌                                                                        | 21/200 [02:41<23:18,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  20: train D loss: 0.6367, train F loss: -0.0705, acc 0.9968\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▉                                                                        | 22/200 [02:49<23:21,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  21: train D loss: 0.6332, train F loss: -0.0723, acc 0.9960\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▎                                                                       | 23/200 [02:57<23:14,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  22: train D loss: 0.6346, train F loss: -0.0679, acc 0.9934\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▋                                                                       | 24/200 [03:05<23:11,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  23: train D loss: 0.6334, train F loss: -0.0802, acc 0.9958\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████▏                                                                      | 25/200 [03:12<22:39,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  24: train D loss: 0.6388, train F loss: -0.0699, acc 0.9920\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▌                                                                      | 26/200 [03:20<22:27,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  25: train D loss: 0.6357, train F loss: -0.0747, acc 0.9928\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████████▉                                                                      | 27/200 [03:28<22:32,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  26: train D loss: 0.6362, train F loss: -0.0886, acc 0.9946\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                     | 28/200 [03:36<22:29,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  27: train D loss: 0.6374, train F loss: -0.0907, acc 0.9948\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▋                                                                     | 29/200 [03:44<22:25,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  28: train D loss: 0.6445, train F loss: -0.0943, acc 0.9938\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▏                                                                    | 30/200 [03:52<22:23,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  29: train D loss: 0.6427, train F loss: -0.0937, acc 0.9932\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▌                                                                    | 31/200 [04:00<22:20,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  30: train D loss: 0.6472, train F loss: -0.1056, acc 0.9954\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                    | 32/200 [04:08<22:16,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  31: train D loss: 0.6486, train F loss: -0.1109, acc 0.9962\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                   | 33/200 [04:15<22:05,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  32: train D loss: 0.6451, train F loss: -0.1134, acc 0.9950\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▊                                                                   | 34/200 [04:23<21:56,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  33: train D loss: 0.6470, train F loss: -0.1177, acc 0.9948\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▏                                                                  | 35/200 [04:31<21:53,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  34: train D loss: 0.6581, train F loss: -0.0923, acc 0.9904\n",
      "156\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▌                                                                  | 36/200 [04:40<21:51,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  35: train D loss: 0.6563, train F loss: -0.1147, acc 0.9908\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                  | 37/200 [04:48<21:45,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  36: train D loss: 0.6462, train F loss: -0.1263, acc 0.9936\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▍                                                                 | 38/200 [04:56<21:40,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  37: train D loss: 0.6446, train F loss: -0.1255, acc 0.9926\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▊                                                                 | 39/200 [05:04<21:32,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  38: train D loss: 0.6526, train F loss: -0.1356, acc 0.9936\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                | 40/200 [05:12<21:21,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  39: train D loss: 0.6438, train F loss: -0.1389, acc 0.9946\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                | 41/200 [05:20<21:11,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  40: train D loss: 0.6599, train F loss: -0.1331, acc 0.9888\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████                                                                | 42/200 [05:27<20:57,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  41: train D loss: 0.6528, train F loss: -0.1475, acc 0.9942\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▍                                                               | 43/200 [05:35<20:44,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  42: train D loss: 0.6472, train F loss: -0.1564, acc 0.9962\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▊                                                               | 44/200 [05:43<20:37,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  43: train D loss: 0.6484, train F loss: -0.1583, acc 0.9964\n",
      "156\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▏                                                              | 45/200 [05:51<20:32,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  44: train D loss: 0.6521, train F loss: -0.1651, acc 0.9964\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▋                                                              | 46/200 [05:59<20:24,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  45: train D loss: 0.6588, train F loss: -0.1531, acc 0.9910\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████                                                              | 47/200 [06:07<20:25,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  46: train D loss: 0.6538, train F loss: -0.1566, acc 0.9934\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▍                                                             | 48/200 [06:16<20:24,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  47: train D loss: 0.6562, train F loss: -0.0795, acc 0.9678\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▊                                                             | 49/200 [06:23<19:55,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  48: train D loss: 0.6515, train F loss: -0.1616, acc 0.9922\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▎                                                            | 50/200 [06:30<19:21,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  49: train D loss: 0.6489, train F loss: -0.1728, acc 0.9936\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▋                                                            | 51/200 [06:38<19:06,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  50: train D loss: 0.6461, train F loss: -0.1801, acc 0.9950\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                            | 52/200 [06:46<19:07,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  51: train D loss: 0.6499, train F loss: -0.1841, acc 0.9938\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▍                                                           | 53/200 [06:54<19:01,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  52: train D loss: 0.6506, train F loss: -0.1871, acc 0.9942\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▊                                                           | 54/200 [07:02<18:56,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  53: train D loss: 0.6524, train F loss: -0.1857, acc 0.9944\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▎                                                          | 55/200 [07:09<18:46,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  54: train D loss: 0.6503, train F loss: -0.1913, acc 0.9936\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▋                                                          | 56/200 [07:17<18:42,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  55: train D loss: 0.6524, train F loss: -0.1893, acc 0.9932\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████                                                          | 57/200 [07:25<18:34,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  56: train D loss: 0.6538, train F loss: -0.2032, acc 0.9950\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▍                                                         | 58/200 [07:33<18:31,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  57: train D loss: 0.6575, train F loss: -0.2038, acc 0.9932\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▉                                                         | 59/200 [07:41<18:24,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  58: train D loss: 0.6633, train F loss: -0.2103, acc 0.9942\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▎                                                        | 60/200 [07:48<18:15,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  59: train D loss: 0.6573, train F loss: -0.2109, acc 0.9936\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▋                                                        | 61/200 [07:56<18:08,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  60: train D loss: 0.6520, train F loss: -0.2165, acc 0.9946\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████                                                        | 62/200 [08:04<18:04,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  61: train D loss: 0.6597, train F loss: -0.2222, acc 0.9944\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▌                                                       | 63/200 [08:12<17:58,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  62: train D loss: 0.6553, train F loss: -0.2240, acc 0.9938\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▉                                                       | 64/200 [08:20<17:50,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  63: train D loss: 0.6617, train F loss: -0.2187, acc 0.9910\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▎                                                      | 65/200 [08:28<17:36,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  64: train D loss: 0.6577, train F loss: -0.2240, acc 0.9924\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▋                                                      | 66/200 [08:36<17:29,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  65: train D loss: 0.6584, train F loss: -0.2386, acc 0.9950\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▏                                                     | 67/200 [08:44<17:26,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  66: train D loss: 0.6523, train F loss: -0.2392, acc 0.9958\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▌                                                     | 68/200 [08:51<17:12,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  67: train D loss: 0.6628, train F loss: -0.2327, acc 0.9916\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▉                                                     | 69/200 [08:59<17:04,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  68: train D loss: 0.6621, train F loss: -0.2462, acc 0.9938\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▎                                                    | 70/200 [09:07<16:54,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  69: train D loss: 0.6550, train F loss: -0.2502, acc 0.9946\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▊                                                    | 71/200 [09:15<16:44,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  70: train D loss: 0.6610, train F loss: -0.2514, acc 0.9932\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▏                                                   | 72/200 [09:22<16:38,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  71: train D loss: 0.6525, train F loss: -0.2498, acc 0.9932\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▌                                                   | 73/200 [09:30<16:24,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  72: train D loss: 0.6589, train F loss: -0.2571, acc 0.9940\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▉                                                   | 74/200 [09:38<16:13,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  73: train D loss: 0.6616, train F loss: -0.2679, acc 0.9950\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▍                                                  | 75/200 [09:46<16:08,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  74: train D loss: 0.6664, train F loss: -0.2597, acc 0.9914\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▊                                                  | 76/200 [09:53<16:03,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  75: train D loss: 0.6644, train F loss: -0.2486, acc 0.9888\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▏                                                 | 77/200 [10:01<15:56,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  76: train D loss: 0.6570, train F loss: -0.2752, acc 0.9952\n",
      "156\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▌                                                 | 78/200 [10:09<15:48,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  77: train D loss: 0.6640, train F loss: -0.2784, acc 0.9938\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▉                                                 | 79/200 [10:17<15:38,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  78: train D loss: 0.6622, train F loss: -0.2770, acc 0.9916\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▍                                                | 80/200 [10:24<15:26,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  79: train D loss: 0.6620, train F loss: -0.2890, acc 0.9964\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                | 81/200 [10:32<15:20,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  80: train D loss: 0.6630, train F loss: -0.2932, acc 0.9958\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▏                                               | 82/200 [10:40<15:19,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  81: train D loss: 0.6619, train F loss: -0.2948, acc 0.9952\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▌                                               | 83/200 [10:48<15:17,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  82: train D loss: 0.6660, train F loss: -0.2789, acc 0.9900\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████                                               | 84/200 [10:56<15:18,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  83: train D loss: 0.6623, train F loss: -0.2931, acc 0.9924\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▍                                              | 85/200 [11:04<15:13,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  84: train D loss: 0.6650, train F loss: -0.2498, acc 0.9864\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▊                                              | 86/200 [11:12<15:09,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  85: train D loss: 0.6543, train F loss: -0.2934, acc 0.9930\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▏                                             | 87/200 [11:20<15:01,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  86: train D loss: 0.6582, train F loss: -0.3077, acc 0.9952\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▋                                             | 88/200 [11:28<14:50,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  87: train D loss: 0.6635, train F loss: -0.3126, acc 0.9940\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████                                             | 89/200 [11:36<14:37,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  88: train D loss: 0.6595, train F loss: -0.3063, acc 0.9926\n",
      "156\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▍                                            | 90/200 [11:44<14:32,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  89: train D loss: 0.6592, train F loss: -0.3178, acc 0.9950\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▊                                            | 91/200 [11:52<14:27,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  90: train D loss: 0.6629, train F loss: -0.3210, acc 0.9942\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▎                                           | 92/200 [12:00<14:21,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  91: train D loss: 0.6667, train F loss: -0.3294, acc 0.9956\n",
      "epoch  92: train D loss: 0.6781, train F loss: -0.2576, acc 0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▋                                           | 93/200 [12:08<14:13,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████                                           | 94/200 [12:16<14:07,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  93: train D loss: 0.6711, train F loss: -0.3119, acc 0.9874\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▍                                          | 95/200 [12:24<14:01,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  94: train D loss: 0.6601, train F loss: -0.3351, acc 0.9952\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▉                                          | 96/200 [12:32<13:54,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  95: train D loss: 0.6619, train F loss: -0.3388, acc 0.9944\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▎                                         | 97/200 [12:40<13:47,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  96: train D loss: 0.6626, train F loss: -0.3450, acc 0.9952\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▋                                         | 98/200 [12:48<13:38,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  97: train D loss: 0.6667, train F loss: -0.3446, acc 0.9942\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                         | 99/200 [12:56<13:27,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  98: train D loss: 0.6669, train F loss: -0.3419, acc 0.9928\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                        | 100/200 [13:04<13:15,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  99: train D loss: 0.6687, train F loss: -0.3492, acc 0.9924\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▍                                       | 101/200 [13:12<13:03,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100: train D loss: 0.6606, train F loss: -0.3547, acc 0.9952\n",
      "152\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▊                                       | 102/200 [13:19<12:53,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101: train D loss: 0.6653, train F loss: -0.3538, acc 0.9930\n",
      "151\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▏                                      | 103/200 [13:27<12:45,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102: train D loss: 0.6698, train F loss: -0.3633, acc 0.9952\n",
      "156\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▌                                      | 104/200 [13:35<12:35,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103: train D loss: 0.6717, train F loss: -0.3683, acc 0.9934\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████                                      | 105/200 [13:43<12:27,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104: train D loss: 0.6669, train F loss: -0.3564, acc 0.9924\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▍                                     | 106/200 [13:51<12:19,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105: train D loss: 0.6678, train F loss: -0.3666, acc 0.9938\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████▊                                     | 107/200 [13:59<12:10,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106: train D loss: 0.6709, train F loss: -0.3731, acc 0.9946\n",
      "155\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▏                                    | 108/200 [14:07<12:04,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107: train D loss: 0.6683, train F loss: -0.3779, acc 0.9938\n",
      "153\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▌                                    | 109/200 [14:14<11:53,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108: train D loss: 0.6720, train F loss: -0.3801, acc 0.9928\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████                                    | 110/200 [14:22<11:40,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109: train D loss: 0.6654, train F loss: -0.3768, acc 0.9938\n",
      "156\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▍                                   | 111/200 [14:30<11:32,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110: train D loss: 0.6726, train F loss: -0.3839, acc 0.9934\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▊                                   | 112/200 [14:37<11:23,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111: train D loss: 0.6664, train F loss: -0.3924, acc 0.9948\n",
      "156\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▏                                  | 113/200 [14:45<11:17,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112: train D loss: 0.6745, train F loss: -0.3529, acc 0.9820\n",
      "154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▌                                  | 114/200 [14:53<11:10,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113: train D loss: 0.6615, train F loss: -0.3808, acc 0.9912\n",
      "70\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▌                                  | 114/200 [14:57<11:16,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\r",
      "72\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15872/1683736261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# You should chooose lamnda cleverly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     train_D_loss, train_F_loss, train_acc = train_epoch(source_dataloader, target_dataloader\n\u001b[0m\u001b[0;32m     63\u001b[0m         , lamb=(2-math.exp(-(0.00330612557*epoch-0.693))))\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15872/1683736261.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(source_dataloader, target_dataloader, lamb)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtotal_hit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0msource_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \"\"\"\n\u001b[0;32m    229\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RGB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \"\"\"\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"transparency\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m                         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m                                 \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecodermaxblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m                             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                                 \u001b[1;31m# truncated png/gif\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "def train_epoch(source_dataloader, target_dataloader, lamb):\n",
    "    '''\n",
    "      Args:\n",
    "        source_dataloader: source data的dataloader\n",
    "        target_dataloader: target data的dataloader\n",
    "        lamb: control the balance of domain adaptatoin and classification.\n",
    "    '''\n",
    "\n",
    "    # D loss: Domain Classifier的loss\n",
    "    # F loss: Feature Extrator & Label Predictor的loss\n",
    "    running_D_loss, running_F_loss = 0.0, 0.0\n",
    "    total_hit, total_num = 0.0, 0.0\n",
    "\n",
    "    for i, ((source_data, source_label), (target_data, _)) in enumerate(zip(source_dataloader, target_dataloader)):\n",
    "\n",
    "        source_data = source_data.cuda()\n",
    "        source_label = source_label.cuda()\n",
    "        target_data = target_data.cuda()\n",
    "        \n",
    "        # Mixed the source data and target data, or it'll mislead the running params\n",
    "        #   of batch_norm. (runnning mean/var of soucre and target data are different.)\n",
    "        mixed_data = torch.cat([source_data, target_data], dim=0)\n",
    "        domain_label = torch.zeros([source_data.shape[0] + target_data.shape[0], 1]).cuda()\n",
    "        # set domain label of source data to be 1.\n",
    "        domain_label[:source_data.shape[0]] = 1\n",
    "\n",
    "        # Step 1 : train domain classifier\n",
    "        feature = feature_extractor(mixed_data)\n",
    "        # We don't need to train feature extractor in step 1.\n",
    "        # Thus we detach the feature neuron to avoid backpropgation.\n",
    "        domain_logits = domain_classifier(feature.detach())\n",
    "        loss = domain_criterion(domain_logits, domain_label)\n",
    "        running_D_loss+= loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Step 2 : train feature extractor and label classifier\n",
    "        class_logits = label_predictor(feature[:source_data.shape[0]])\n",
    "        domain_logits = domain_classifier(feature)\n",
    "        # loss = cross entropy of classification - lamb * domain binary cross entropy.\n",
    "        #  The reason why using subtraction is similar to generator loss in disciminator of GAN\n",
    "        loss = class_criterion(class_logits, source_label) - lamb * domain_criterion(domain_logits, domain_label)\n",
    "        running_F_loss+= loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_F.step()\n",
    "        optimizer_C.step()\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        optimizer_F.zero_grad()\n",
    "        optimizer_C.zero_grad()\n",
    "\n",
    "        total_hit += torch.sum(torch.argmax(class_logits, dim=1) == source_label).item()\n",
    "        total_num += source_data.shape[0]\n",
    "        print(i, end='\\r')\n",
    "\n",
    "    return running_D_loss / (i+1), running_F_loss / (i+1), total_hit / total_num\n",
    "\n",
    "# train 200 epochs\n",
    "for epoch in tqdm(range(200)):\n",
    "    # You should chooose lamnda cleverly.\n",
    "    train_D_loss, train_F_loss, train_acc = train_epoch(source_dataloader, target_dataloader\n",
    "        , lamb=(2-math.exp(-(0.00330612557*epoch-0.693))))\n",
    "\n",
    "    torch.save(feature_extractor.state_dict(), f'extractor_model.bin')\n",
    "    torch.save(label_predictor.state_dict(), f'predictor_model.bin')\n",
    "\n",
    "    print('epoch {:>3d}: train D loss: {:6.4f}, train F loss: {:6.4f}, acc {:6.4f}'.format(epoch, train_D_loss, train_F_loss, train_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8_-0iSSje4w"
   },
   "source": [
    "# Inference\n",
    "\n",
    "就跟前幾次作業一樣。這裡我使用pd來生產csv，因為看起來比較潮(?)\n",
    "\n",
    "此外，200 epochs的Accuracy可能會不太穩定，可以多丟幾次或train久一點。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Wly5AgH2jePv"
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "label_predictor.eval()\n",
    "feature_extractor.eval()\n",
    "for i, (test_data, _) in enumerate(test_dataloader):\n",
    "    test_data = test_data.cuda()\n",
    "\n",
    "    class_logits = label_predictor(feature_extractor(test_data))\n",
    "\n",
    "    x = torch.argmax(class_logits, dim=1).cpu().detach().numpy()\n",
    "    result.append(x)\n",
    "\n",
    "import pandas as pd\n",
    "result = np.concatenate(result)\n",
    "\n",
    "# Generate your submission\n",
    "df = pd.DataFrame({'id': np.arange(0,len(result)), 'label': result})\n",
    "df.to_csv('DaNN_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtXnEMUNCE78"
   },
   "source": [
    "# Training Statistics\n",
    "\n",
    "- Number of parameters:\n",
    "  - Feature Extractor: 2, 142, 336\n",
    "  - Label Predictor: 530, 442\n",
    "  - Domain Classifier: 1, 055, 233\n",
    "\n",
    "- Simple\n",
    " - Training time on colab: ~ 1 hr\n",
    "- Medium\n",
    " - Training time on colab: 2 ~ 4 hr\n",
    "- Strong\n",
    " - Training time on colab: 5 ~ 6 hrs\n",
    "- Boss\n",
    " - **Unmeasurable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duk7k43Am9xH"
   },
   "source": [
    "# Learning Curve (Strong Baseline)\n",
    "* This method is slightly different from colab.\n",
    "\n",
    "![Loss Curve](https://i.imgur.com/vIujQyo.png)\n",
    "\n",
    "# Accuracy Curve (Strong Baseline)\n",
    "* Note that you cannot access testing accuracy. But this plot tells you that even though the model overfits the training data, the testing accuracy is still improving, and that's why you need to train more epochs.\n",
    "\n",
    "![Acc Curve](https://i.imgur.com/4W1otXG.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6UfXzef-wNl"
   },
   "source": [
    "# Special Thanks\n",
    "下面是原本台大助教提供的參考作業。\n",
    "\n",
    "[NTU_r08942071_太神啦 / 組長: 劉正仁同學](https://drive.google.com/open?id=11uNDcz7_eMS8dMQxvnWsbrdguu9k4c-c)\n",
    "\n",
    "[NTU_r08921a08_CAT / 組長: 廖子毅同學](https://drive.google.com/open?id=1xIkSs8HAShdcfV1E0NEnf4JDbL7POZTf)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ML22HW07.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
